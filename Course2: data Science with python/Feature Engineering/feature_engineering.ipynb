{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b98273f",
   "metadata": {},
   "source": [
    "## Feature Engineering \n",
    "\n",
    "- It refers to the process of selecting, modifying, or creating new features (variables) from the raw data to improve the performance of machine learning models.\n",
    "- It involves transforming the data into a more suitable format, making it easier for models to learn patterns and make accurate predictions.\n",
    "- It is a critical step in the data preprocessing pipeline and plays a key role in the success of machine learning projects.\n",
    "\n",
    "## Transforming Variables\n",
    "- Transforming variables is a crucial aspect of feature engineering that involves modifying the scale, distribution, or nature of variables to meet certain assumptions or to make them more suitable for analysis or modeling.\n",
    "\n",
    "- Techniques for transforming variables:\n",
    "\n",
    "    - Log transformation\n",
    "    - Square root transformation\n",
    "    - Box-cox transformation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df= pd.read_csv(\"HousePrices.csv\")\n",
    "\n",
    "# Example: Creating a new feature 'total_rooms' by adding bedrooms and bathrooms\n",
    "df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
    "\n",
    "\n",
    "#Log Transformation\n",
    "#Log transformation is useful for handling skewed data or reducing the impact of outliers. It applies the natural logarithm to the variable values and makes highly skewed distributions less skewed. \n",
    "\n",
    "# Logarithmic transformation of the 'price' column\n",
    "df['log_price'] = np.log(df['price'])\n",
    "\n",
    "\n",
    "\n",
    "# Square Root Transformation\n",
    "# Square root transformation, like log transformation, stabilizes variance and addresses skewed distributions. \n",
    "# Square root transforming the 'price' variable\n",
    "df['SquareRoot_price'] = np.sqrt(df['price'])\n",
    "\n",
    "# Displaying the DataFrame with the new feature\n",
    "print(\"DataFrame with square root transformed 'price':\")\n",
    "print(df[['price', 'SquareRoot_price']])\n",
    "\n",
    "\n",
    "#Box-Cox TransformationThe box-cox transformation is a family of power transformations that includes log and square root transformations.\n",
    "# It can handle a broader range of data distributions.\n",
    "# Ensuring positive data is crucial for the Box-Cox transformation because it involves taking the logarithm, which is undefined for zero or negative values. \n",
    "# Adding a constant helps avoid mathematical errors and ensures the transformation can be applied effectively.\n",
    "\n",
    "from scipy.stats import boxcox\n",
    "# Applying Box-Cox transformation to 'sales' variable\n",
    "df['BoxCox_Price'], _ = boxcox(df['sqft_living'])\n",
    "\n",
    "# Displaying the DataFrame with the Box-Cox transformed 'sales' variable\n",
    "print(\"DataFrame with box-cox transformed price:\")\n",
    "print(df[['sqft_living', 'BoxCox_Price']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6613d",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "- Feature scaling is a technique used in machine learning and data preprocessing to standardize or normalize the range of independent variables or features of a dataset.\n",
    "- Min-max scaling transforms data to a specific range, typically between 0 and 1, preserving the relative differences between values. This normalization technique is ideal for datasets with known bounds, ensuring that all values are rescaled proportionally to fit within the specified range.\n",
    "- Standard scaling is preferable for normally distributed data to maintain mean-centeredness and consistent standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scaling numeric features using min-max scaling\n",
    "scaler = MinMaxScaler()\n",
    "df[['sqft_living', 'sqft_lot']] = scaler.fit_transform(df[['sqft_living', 'sqft_lot']])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24e6b10",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "- Label encoding is a technique used to convert categorical labels into a numeric format, making it suitable for machine learning algorithms that require numerical input.\n",
    "- In Label encoding, each category is assigned an integer value\n",
    "- this is useful when dealing with ordinal categorical data, where the order of categories matters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc41d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'size': ['small', 'medium', 'large', 'medium', 'small']}\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "# Before label encoding\n",
    "print(\"Original DataFrame:\")\n",
    "print(df1)\n",
    "\n",
    "# Apply label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df1['size_encoded'] = label_encoder.fit_transform(df1['size'])\n",
    "\n",
    "# After label encoding\n",
    "print(\"\\nDataFrame after label encoding:\")\n",
    "print(df1)\n",
    "\n",
    "\n",
    "\n",
    "# Demonstrating label encoding using csv file\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encoding for the 'city' column\n",
    "label_encoder = LabelEncoder()\n",
    "df['city_encoded'] = label_encoder.fit_transform(df['city'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fb58fd",
   "metadata": {},
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "- One-hot encoding is a technique to represent categorical variables as binary vectors.\n",
    "- It is particularly useful when dealing with nominal categorical data, where there is no inherent order among categories.\n",
    "- In one-hot encoding, each category is transformed into a binary column, and only one column in each set of binary columns is hot(or 1) to indicate the presence of that category.\n",
    "-  It increases dataset dimensionality, facilitating categorical data representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7bc11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'color': ['red', 'blue', 'green', 'red', 'green']}\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "# Before one-hot encoding\n",
    "print(\"Original DataFrame:\")\n",
    "print(df2)\n",
    "\n",
    "# Apply one-hot encoding\n",
    "df2_encoded = pd.get_dummies(df2, columns=['color'], prefix='color')\n",
    "\n",
    "# After one-hot encoding\n",
    "print(\"\\nDataFrame after one-hot encoding:\")\n",
    "print(df2_encoded)\n",
    "\n",
    "\n",
    "# Demonstrating one-hot encoding using csv file\n",
    "# One-Hot Encoding for the 'view' column\n",
    "df_encode = pd.get_dummies(df, columns=['price'], prefix='price')\n",
    "\n",
    "# After one-hot encoding\n",
    "print(\"\\nDataFrame after one-hot encoding:\")\n",
    "print(df_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e92a07",
   "metadata": {},
   "source": [
    "## Hashing\n",
    "- It is a technique to convert input data (of variable length) into a fixed-length string of characters, a hash code.\n",
    "- The hash function takes an input (or message) and returns a fixed-size string of characters, typically a hexadecimal number.\n",
    "- commonly used for indexing data structures, checking data integrity, and hashing passwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370fc08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of hashing in Python\n",
    "data = \"Hello, Hashing!\"\n",
    "\n",
    "# Using the hash() function\n",
    "hash_value = hash(data)\n",
    "\n",
    "print(f\"Original data: {data}\")\n",
    "print(f\"Hash value: {hash_value}\")\n",
    "\n",
    "\n",
    "# Demonstrating hashing using csv file\n",
    "# Hashing for the 'street' column\n",
    "df['street_hashed'] = df['street'].apply(hash)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79963b6c",
   "metadata": {},
   "source": [
    "## Hashlib Module\n",
    "## cryptographic hash algorithms\n",
    "-  The hashlib module in Python is used for generating hash values. It offers interfaces to different cryptographic hash algorithms like MD5, SHA-1, SHA-256, SHA-384, and SHA-512.\n",
    "- It enables the efficient use of hash functions, ensuring secure computations.\n",
    "- It provides reliability for hash-related operations.\n",
    "- It is widey used for cryptographic operations, data integrity, and password hashing.\n",
    "- It ensures convenience and robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of hashlib module in Python\n",
    "import hashlib\n",
    "\n",
    "# Input data\n",
    "data = b'Hello, world!'\n",
    "print(f\"Original data: {data.decode()} \\n\")\n",
    "\n",
    "# Calculate MD5 hash\n",
    "md5_hash = hashlib.md5(data).hexdigest()\n",
    "print(\"MD5 Hash:\", md5_hash)\n",
    "\n",
    "# Calculate SHA-1 hash\n",
    "sha1_hash = hashlib.sha1(data).hexdigest()\n",
    "print(\"SHA-1 Hash:\", sha1_hash)\n",
    "\n",
    "# Calculate SHA-256 hash\n",
    "sha256_hash = hashlib.sha256(data).hexdigest()\n",
    "print(\"SHA-256 Hash:\", sha256_hash)\n",
    "\n",
    "# Calculate SHA-384 hash\n",
    "sha384_hash = hashlib.sha384(data).hexdigest()\n",
    "print(\"SHA-384 Hash:\", sha384_hash)\n",
    "\n",
    "# Calculate SHA-512 hash\n",
    "sha512_hash = hashlib.sha512(data).hexdigest()\n",
    "print(\"SHA-512 Hash:\", sha512_hash)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Demonstrating MD5 hash function using csv file for the 'street' column\n",
    "\n",
    "street_column = df['street']\n",
    "hashed_streets = street_column.apply(lambda x: hashlib.md5(x.encode()).hexdigest())\n",
    "\n",
    "# Replace the original street values with hash values\n",
    "df['hashed_street'] = hashed_streets\n",
    "\n",
    "# Optionally, write the updated DataFrame back to a CSV file\n",
    "df.to_csv('hashed_file.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a6707",
   "metadata": {},
   "source": [
    "## Grouping Operations\n",
    "\n",
    "- Grouping operations involve splitting a dataset into groups based on some criteria, applying a function to each group independently, and then combining the results.\n",
    "- This is a crucial step in data analysis and manipulation, allowing for insights into the data at a more granular level.\n",
    "- Grouping operations are commonly combined with aggregate functions to summarize data within each group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec199458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'Category': ['Electronics', 'Clothing', 'Electronics', 'Clothing', 'Electronics'],\n",
    "        'Revenue': [500, 300, 700, 400, 600]}\n",
    "\n",
    "df3 = pd.DataFrame(data)\n",
    "\n",
    "# Grouping by 'Category' and calculating total revenue for each category\n",
    "grouped_df3 = df3.groupby('Category')['Revenue'].sum().reset_index()\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df3)\n",
    "print(\"\\nGrouped DataFrame with total revenue:\")\n",
    "print(grouped_df3)\n",
    "\n",
    "\n",
    "\n",
    "# Grouping by 'city' and calculating the average price\n",
    "df_grouped = df.groupby('city')['price'].mean().reset_index()\n",
    "print(df_grouped)\n",
    "\n",
    "\n",
    "\n",
    "# Grouping by 'city' and calculating the maximum price\n",
    "df_max_price = df.groupby('city')['price'].max().reset_index()\n",
    "print(df_max_price)\n",
    "\n",
    "\n",
    "# Grouping by 'city' and calculating the minimum price\n",
    "df_min_price = df.groupby('city')['price'].min().reset_index()\n",
    "print(df_min_price)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
