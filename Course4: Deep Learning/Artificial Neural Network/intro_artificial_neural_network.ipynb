{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264416f3",
   "metadata": {},
   "source": [
    "## Definition of Artificial Neuron\n",
    "- artificial neurons are closely related to biological neurons, where neurons takes input, adds wights to them separately, sums them up, and passes this sum through a transfer function to produce a nonlinear output. \n",
    "- process the input signal with a certain threshold, with binary outputs. \n",
    "\n",
    "##Â Biological Neurons vs Artificial Neurons\n",
    "- Biological Neurons, have cell nucleus that correspons to Artificial Neurons Node.\n",
    "- Biological Neurons, have Dendrites that correspons to Artificial Neurons Inpute.\n",
    "- Biological Neurons, have Synapes that correspons to Artificial Neurons weights and interconnections.\n",
    "- Biological Neurons, have Axon that correspons to Artificial Neurons Output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfa72b8",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "- Neural networks consists of interconnected computations modules that simulate the behavior of biolofical neurons. \n",
    "- each nueral network consists of multiple node layers: Input layers, one or more hidden layers, and output layers. \n",
    "- Artificial Neural Networks process information using:\n",
    "    - inputs that are passed into the first layer\n",
    "    - Each individual neuron receives inputs and assigns a weight to each of the inputs\n",
    "    - The neurons generate output based on the assigned weights\n",
    "    - the outputs from the first layer are forwarded to the second layer for further processing\n",
    "    - the process continues until the final output is produced.\n",
    "\n",
    "### Types of Neural Networks\n",
    "- Perceptrons\n",
    "- Multilayer perceptron\n",
    "- Deep Neural Networks or DNNs \n",
    "- Convolutional neural networks or CNNs\n",
    "- Recurrent neural networks or RNNs\n",
    "\n",
    "- `Perceptrons`: the simplest type of artifical neural networks and is used for binary predictions. A perceptron can only work if the data is linearly separable.\n",
    "\n",
    "- `Multilayer Perceptron (MLP)`: multiple layers of perceptrons. The inputs pass through each layer, and the outputs of the last layer are the final outputs of the multilayer perceptron. it can handle more complex problems by learning non-linear relationships. \n",
    "\n",
    "- `Deep Neural Networks (DNN)`: a Deep neural network is a multilayered computational model that processes data in a layered manner, refining information at each layer, similar to how the human brain works. The depth of the deep neural network allows for addressing complex problems, like image processing and speech recognition. And they consists of multple hidden layers\n",
    "\n",
    "- `Convolutional Neural Network (CNN)`: Convolutional Neural Networks (CNNs) analyze visual data and are inspired by the brain's visual cortex. Effective for recognizing patterns in images. An example is image classification. \n",
    "\n",
    "- `Recurrent Neural Network (RNN)`: Reccurent Neural Networks (RNNs) handle sequential data, suitable for time series and language modeling tasks. It maintains a memory from the previous inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2074b1a",
   "metadata": {},
   "source": [
    "## Combination of Neural Network layers\n",
    "- The number of layers in a Conlolutional Neural Network (CNNs) or Recurrent Neural Network (CNNs) depends on the complexity of the tasks and data, the deeper the architecture the more likely it is to solve complex problems. \n",
    "\n",
    "    - The input layer depicts the minensions of the input vectors\n",
    "    - The hidden layers depicts the intermediary nodes that divide the input space into regions with soft boundaries.\n",
    "    - The output layer depicts the output of the neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2500e7",
   "metadata": {},
   "source": [
    "## Perceptrons\n",
    "- The perceptron is a fundamental type of artificial neural network designed for binary classification tasks. It computes a weighted sum of its inputs, which is then passed through a step function to determine the output class\n",
    "\n",
    "- the importance of the amount of inputs is determined by the corresponding weights\n",
    "- the output is a sum of inputs multiplied by their corresponding weights. \n",
    "- the weights of the perceptron are trained with different sets of inputs\n",
    "    - every passage of inputs, the perceptron produces the output as either 0 or 1, which is compared to the ground truth. \n",
    "    - the weights are adjusted accordingly for better predictions\n",
    "    - a perceptron works well when the classes in the data are linearly separable. \n",
    "\n",
    "## Components of a perceptron\n",
    "- Inputs: a set of values for which one needs to predict the output value. \n",
    "\n",
    "- weights: set of real values that are associated with each feature and state the importance of the feature in predicting the final value\n",
    "\n",
    "- Bias: used for shifting the activation function left or right and can be referred to as a y-intercept in the line equation.\n",
    "\n",
    "- Summantion function: binds the weights and inputs together and finds their sum.\n",
    "\n",
    "- Activation function: is used to depict nonlinearity in the model. \n",
    "\n",
    "## Feedforward Neural Network\n",
    "- Feedforward neural networks, also known as feedforward nets, are a type of artificial neural network (ANN) where information flows only in one directiion, from the input layer to the output layer, without any feedback connections. \n",
    "\n",
    "- It cannot remember anything that happened in the recent past, except its training.\n",
    "- since it only considers the current input, it has no notion of order in time. \n",
    "- The information moves straight through the network and never touches a node twice.\n",
    "- no memory of th einput it receives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cdc9c3",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "- Before producing an output from a perceptron, it is important to decide whether to activate the neuron or not. This is where the activation function comes into play. \n",
    "\n",
    "- The sum of products of inputs and weights is passed to an activation function. \n",
    "- the activation functions are mathematical equations that determine the output of a neural network model. And plays a crucial role in a neural networks ability to converge and affect the convergence speed. \n",
    "- The activation function is needed in neural networks to introduce non-linearity and enable the model to learn complex relationships and make more expressive predictions. \n",
    "- the activation functions limit the output by preventing large positive or negative values in neural networks\n",
    "\n",
    "\n",
    "## Types of Activation Functions\n",
    "- Step functions\n",
    "- Sigmoid function\n",
    "- ReLU\n",
    "- Softmax function\n",
    "\n",
    "- Step functions: A perceptron gets activated whenever the sum of weighted inputs is non-zero and and positive.\n",
    "\n",
    "- Sigmoid function: a activation function that produces an output in the range of 0 to 1, making it useful for binary classification tasks. \n",
    "\n",
    "- Rectified Linear Unit (ReLU): If the value of the input to a neuron is zero or less, rectified linear unit(ReLU) assigns 0 as the output value. If not, the output value is equal to the input\n",
    "\n",
    "- Softmax function: useful for handling multiclass classification problems. It is found in the output layer of the image classification problems. It normalizes outputs for each class to fall between 0 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f4b757",
   "metadata": {},
   "source": [
    "## phases of a perceptron model\n",
    "- training a perceptron model involves the forward propagation (forward pass) and backward propagation (backprop) phases.\n",
    "\n",
    "## backpropagation\n",
    "- the network learns from input data or training examples to generalize and acquire knowledge\n",
    "- by adjusting weights and biases, it aims to find a line, plane, or hyperplane that can accurately separate different classes. \n",
    "- the network configures itself through training to effectively solve the problem at hand.\n",
    "\n",
    "## backpropagation algorithm\n",
    "- backpropagation process within training a neural network.\n",
    "1. initialized the weights and the threshold\n",
    "2. provide the input and calculate the output\n",
    "3. update the weights\n",
    "4. repeat the initial steps\n",
    "\n",
    "- once the model receives the sum of the weighted inputs, it is passed through the activation function, which gives 0 or 1 as the final output of the perceptron modle for the given inputs. the output value is compared with the ground truth value, and an error is computed. \n",
    "\n",
    "- to minimize the error, the neural network traverses back to change the weights of the input neurons, resulting in new weights, predictions and continues until the error cannot be reduced any further. \n",
    "\n",
    "## Loss function and cost function\n",
    "\n",
    "- Loss function: in deep learning models, while predicting, the output deviates from the actual value, the quantitative measure of this difference is called loss. \n",
    "    - Example: if the expected value is 10 and there was a value of 8 predicted then the loss will be 2\n",
    "\n",
    "- The loss function, measures the discrepancy between the predicted outputs of a machine learning model and the true values of the training data. \n",
    "\n",
    "- Cost function: aggregates the different for the entire training dataset\n",
    "    - to measure the model's accuracy, compare the predicted results with the actual values. the greater the discrepancy between these two, the higher the error metric will be. \n",
    "\n",
    "## Gradient Descent\n",
    "- a linear regression model finds the equation of a straight line that is used to estimate the output. the linear regression focuses on finding hte best fit line for regression tasks, while simple perceptron aims to classify data into different classes. \n",
    "\n",
    "- Gradient Descent is a optimization algorithm used to minimize loss function, working by repetitively adjusting the input variables in the direction that reduces loss function's value the most. \n",
    "\n",
    "## Gradient Ascent\n",
    "- The Y axis is the function value. The gradient is used to determine whether the weights should change.\n",
    "\n",
    "- If the gradient is positive, then the weights are decreased.\n",
    "- If the gradient is negative, then the weights are increased.\n",
    "- The object of gradient ascent isnt to minimize but to maximize a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0dcb5",
   "metadata": {},
   "source": [
    "## vanishing gradient\n",
    "- the vanishing gradient problem occurs during the training of deep neural networks, those using the gradient-based learning methods and backpropagation. \n",
    "\n",
    "- gradients of the networks output with respect to the parameters in the earlier layers are calculated during training to update the parameters. However, if the gradients are very small, (close to zero), they effectively prevent weights from changing their values, which means that the network stops learning or learns verly slowly. \n",
    "\n",
    "## Exploding Gradient\n",
    "- during training, this often leads to a scenario where the model fails to converge, meaning the weights can diverge and the cost function can be infinitely large. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
