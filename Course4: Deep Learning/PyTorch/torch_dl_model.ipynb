{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iO5slsKdOT7S"
   },
   "source": [
    "## Steps to be followed:\n",
    "\n",
    "1. Import necessary libraries\n",
    "2. Data Preprocessing Setup\n",
    "3. Load Datasets\n",
    "4. Initialize DataLoaders\n",
    "5. Define the CNN Model\n",
    "6. Set Up Loss Function and Optimizer\n",
    "7. Training the Model\n",
    "8. Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4mEkTO1JYMj"
   },
   "source": [
    "### Step 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 12709,
     "status": "ok",
     "timestamp": 1719131392079,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "dbhIGhSZHPD-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exj9jhx6JfOf"
   },
   "source": [
    "### Step 2:  Data Preprocessing Setup\n",
    "- Define transformations for the input data:\n",
    "     - `ToTensor():` Converts image data from PIL format or NumPy arrays to PyTorch tensors.\n",
    "     - `Normalize((0.5,), (0.5,)):` Normalizes tensor images using mean = 0.5 and std = 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1719131395723,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "sbFO3iXEHQI3"
   },
   "outputs": [],
   "source": [
    "# Data preprocessing: normalization\n",
    "transform_nm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w5vNdd0KqpK"
   },
   "source": [
    "### Step 3: Load Datasets\n",
    "- **Train Dataset:** Load FashionMNIST training data, applying the defined transformations.\n",
    "- **Test Dataset:** Load FashionMNIST test data similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIfqZRn3K7cF"
   },
   "source": [
    "### Step 4: Initialize DataLoaders\n",
    "- `Training DataLoader:` Batches, shuffles, and prepares training data for processing in the model.\n",
    "- `Testing DataLoader:` Batches and prepares test data for evaluation (shuffling is not necessary for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1719131419999,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "JZaKpv8_K5M4",
    "outputId": "d2713b1f-0018-4d5b-bf1b-d0317cdb703b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 60000 samples\n",
      "Testing data: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "train_loader_nm = torch.utils.data.DataLoader(train_dataset_nm, batch_size=32, shuffle=True)\n",
    "test_loader_nm = torch.utils.data.DataLoader(test_dataset_nm, batch_size=32, shuffle=False)\n",
    "\n",
    "# Printing the shape of the datasets\n",
    "print(f'Training data: {len(train_dataset_nm)} samples')\n",
    "print(f'Testing data: {len(test_dataset_nm)} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P76J4B0LXcN"
   },
   "source": [
    "### Step 5: Define the CNN Model\n",
    "- **Model Class Initialization:** Set up the neural network structure with layers defined in the `__init__` method.\n",
    "- **Layers:** Include one convolutional layer, one pooling layer, and two fully connected layers.\n",
    "- **Data Flow through Layers:** Define how data moves through the model using the forward method, incorporating activations (ReLU) and pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1719131442463,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "M7B9NI0GHW6N"
   },
   "outputs": [],
   "source": [
    "# Define a convolutional neural network for classifying FashionMNIST dataset images\n",
    "class FashionMNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc_hidden = nn.Linear(13*13*32, 100)\n",
    "        self.fc_output = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 13*13*32)\n",
    "        x = self.fc_hidden(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc_output(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrV40jK5L3ky"
   },
   "source": [
    "### Step 6: Set Up Loss Function and Optimizer\n",
    "\n",
    "- **CrossEntropyLoss:** Used for multi-class classification tasks.\n",
    "- **Adam Optimizer:** A method for stochastic optimization with a set learning rate of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1719131453354,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "lYQXFP23HcoL"
   },
   "outputs": [],
   "source": [
    "model = FashionMNISTCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "568tU_i9MZ5D"
   },
   "source": [
    "### Step 7: Training the Model and saving it at each epoch\n",
    "\n",
    "- **Epoch Iteration:** Loop through the dataset multiple times (epochs).\n",
    "- **Batch Processing:** For each batch in the DataLoader, perform forward pass, loss calculation, backpropagation, and parameter update.\n",
    "- **Save Model State:** Save the model after training to reuse it later without needing to retrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 498399,
     "status": "ok",
     "timestamp": 1719132041602,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "hngY_lgtf8_I",
    "outputId": "27ecbc77-994c-4cdc-9757-92d7ef1776a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.39879183058540024, Train Accuracy: 85.74666666666667%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 2/10, Loss: 0.26612817190289495, Train Accuracy: 90.37333333333333%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 3/10, Loss: 0.2216284805228313, Train Accuracy: 91.945%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 4/10, Loss: 0.1883942069063584, Train Accuracy: 93.05%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 5/10, Loss: 0.1620183053433895, Train Accuracy: 94.01166666666667%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 6/10, Loss: 0.13680088447729746, Train Accuracy: 94.945%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 7/10, Loss: 0.1175761468090117, Train Accuracy: 95.71%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 8/10, Loss: 0.09986156567347547, Train Accuracy: 96.26666666666667%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 9/10, Loss: 0.08623724563966195, Train Accuracy: 96.845%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 10/10, Loss: 0.074453572653234, Train Accuracy: 97.26166666666667%\n",
      "Model saved to ./mnist_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Training the model for 10 epochs\n",
    "# Define the path for saving the model\n",
    "model_path = './mnist_model.pth'\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images_nm, labels_nm in train_loader_nm:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs_nm = model(images_nm)\n",
    "        loss = criterion(outputs_nm, labels_nm)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted_train = torch.max(outputs_nm.data, 1)\n",
    "        total_train += labels_nm.size(0)\n",
    "        correct_train += (predicted_train == labels_nm).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader_nm)}, Train Accuracy: {train_accuracy}%\")\n",
    "\n",
    "    # Save the model at the end of each epoch\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmCNF_mxMu5X"
   },
   "source": [
    "### Step 8:  Evaluate the Model\n",
    "- **Switch to Evaluation Mode:** Ensure the model is in eval mode to disable dropout or batch norm effects during testing.\n",
    "- **Accuracy Calculation:** Compare the model’s output to the true labels, calculate overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5505,
     "status": "ok",
     "timestamp": 1719132176590,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "zFubvmv-Hfmx",
    "outputId": "847acb15-ad13-43cb-9aa5-730f46430fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set: 91.45%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images_nm, labels_nm in test_loader_nm:\n",
    "        outputs_nm = model(images_nm)\n",
    "        _, predicted = torch.max(outputs_nm.data, 1)\n",
    "        total += labels_nm.size(0)\n",
    "        correct += (predicted == labels_nm).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Model accuracy on test set: {accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
