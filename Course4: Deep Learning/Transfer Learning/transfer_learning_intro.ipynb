{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f3f6c2",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "- It is a deep learning techniqe where a model developed for one task is reused as the starting point for another model. The latter part of this pre-trained model is then fined-tuned or adapted to suit the specific requirements of the new task. \n",
    "\n",
    "## Transfer Learning in Deep Learning Model\n",
    "Key aspects: \n",
    "\n",
    "- Reuse the pre-trained models\n",
    "- Retrain the latter layers for new tasks\n",
    "- Leverages learned features for a wide range of tasks, including but not limited to object recognition\n",
    "\n",
    "## Why use Transfer Learning\n",
    "- Faster training,  speeds up training by reusing pre-trained model knowledge\n",
    "- Improved performance with less training time and resources\n",
    "- Handling small datasets is useful when the new task has a small dataset\n",
    "- Domain adaptation allows models to adapt to new domains or different data distributions\n",
    "- Transfer of knowledge facilitates the insights gained from one task to another\n",
    "- Resource efficiency reduces data annotation needs by utilizing pre-trained models\n",
    "\n",
    "## scenarios of transfer learning:\n",
    "- `positive transfer learning`: Positive transfer learning refers to aa situation where knowledge or experience gained from one task improves performance on a different, related task\n",
    "    - example: a model trained to detect one type of cancer cell may also perform well at detecting variants of those cancer cells in the future\n",
    "\n",
    "- `negative transfer learning`: Negative transfer learning refers to a situation where knowledge or experience gained from one task hinders performance of a different, unrelated task. \n",
    "    - If negative transfer learning is observed, it may be beneficial to conduct further training. \n",
    "\n",
    "## selecting pre-trained models \n",
    "- pre trained models are pre built deep learning models trained on large datasets, enabling efficient transfer learning for improved performance on new tasks. \n",
    "\n",
    "## factors of pre trained model\n",
    "\n",
    "- `Model size:` model size is the most crucial part of a model, it determines the system storage capacity. \n",
    "    - for object detection with an edge device, a small model is preferable to a heavy model.\n",
    "\n",
    "- `Extension of the model`: It reflects the framework on which the model was trained \n",
    "    - if the model is trained with TensorFlow, the file extension is typically .h5, and if it is trained with Pytorch, it is typically .pth. The choice of a pre-trained model depends on the framework being worked \n",
    "\n",
    "- `input of the model`: Each model has its own input requirements, which should be ensured in the preprocessing phase. \n",
    "\n",
    "- `Output of the model`: After successful input processing, the model outputs can be interpreted to provide the desired result. \n",
    "\n",
    "- `Model specifications and accuracy`: specifications vary between pre-trained models based on the tasks to be performed. \n",
    "\n",
    "- `Compare and contrast`: After evaluating all the factors, the models under consideration are compared. \n",
    "    - Speed: model's prediction time, \n",
    "    - accuracy: frequency of correct predictions, balanced with speed and size. \n",
    "    - size: Computational and memory demands of the model based on deployment contraints. \n",
    "\n",
    "\n",
    "## Pre-trained model list\n",
    "\n",
    "- models for image domain\n",
    "        `Face detection`: \n",
    "    1. MTCNN (multi-task cascaded convolutional networks) is a deep learning model specifically designed for face detection. \n",
    "    2. Inception-ResNet is a hybrid model that combines the inception and resnet architectures\n",
    "    3. MobileNet is quick and effective for smartphones with limited resources\n",
    "\n",
    "        `object detection`: \n",
    "    1. Detectron2 is an object detection framework developed by Facebook AI research\n",
    "    2. YOLOv5 (you only look once) is an object detection algorithm known for its real-time processing speed\n",
    "    3. InceptionResNetV2 is a convolutional neural network architecture that combines the inception and resnet modules\n",
    "\n",
    "        `Image segmentation`:\n",
    "    1. Mask RCNN is an object detection and instance segmentation model.\n",
    "    2. UNet is a popular model architecture used for image segmentation tasks. \n",
    "    3. MANet (Microscopy Adaptive Network is a deep learning model designed specifically for microscopy image analysis tasks.)\n",
    "    4. LinkNet is a lightweight and efficient model architecture for semantic segmentation\n",
    "    5. DeepLabv3 is a widely adopted model for semantic image segmentation\n",
    "\n",
    "        `Image classification`:\n",
    "    1. RegNetY is designed for high performance an dcomputational efficiency in CNN architectures\n",
    "    2. ResNet-50 revolutionized computer vision with deep architecture and skip connections\n",
    "    3. VGG-16 isknown for its simplicity and effectiveness in image classfication tasks with deep CNNs\n",
    "    4. EfficientNet achieves performance while being computationally efficient in CNN architectures\n",
    "\n",
    "        `Pose detection`:\n",
    "    1. MoveNet is a lightweight pose estimation model designed for accurate human pose detection\n",
    "    2. OpenPose is popular framework for keypoint detection and action recognition. \n",
    "\n",
    "\n",
    "- models for text domian\n",
    "        `classification models`:\n",
    "    1. XLNet: uses permutation-based training to improve contextual learning, suitable for tasks like sentiment analysis and spam detection\n",
    "    2. ERNIE: integrates structured knowledge, outperforming BERT and XLNet in various bencharmarks, making it ideal for relation extraction and sentiment analysis. \n",
    "\n",
    "        `embedding models`:\n",
    "    1. BERT: known for its bidirectional training and contextual understand. It is used in NER, question answering, and sentiment analysis\n",
    "    2. Electra: is efficient pre training method with strong performace in text embeddings tasks. \n",
    "\n",
    "        `text generation models`: \n",
    "    1. SmartReply: is a text generation model developed by Google that provides automated suggestions for short message responese.\n",
    "    2. RoBERTa: is a state of the art text generation model based on the BERT architecture.\n",
    "\n",
    "        `text based question answering model`:\n",
    "    1. TF2NQ: is a text based question answering model specifically designed for the Natural Questions dataset\n",
    "\n",
    "        `text language models`\n",
    "    1. GPT-4: superior in handing longer texts, multilingual support, and factual accuracy, useful for language translation and summarization\n",
    "    2. Enformer: is a text model with a transformer based architecture and enhanced long range context handling. \n",
    "\n",
    "- models for audio domian\n",
    "        `Audio classification`:\n",
    "    1. YAMNet is designed to classify audio signals into a wide range of sound categories, including environmental sound, musical instruments, and human actions. \n",
    "\n",
    "        `audio embedding`:\n",
    "    1. Trill is an audio embedding model that learns tranferable representations from speech data.\n",
    "    2. OpenL3 is an open-source python library that computes deep audio and image embeddings. It is based on the look, listen, and learn (L3) approach, which uses both audio and visual data to learn useful representations. \n",
    "\n",
    "        `Audio pitch extraction`:\n",
    "    1. CREPE: is a deep convolutional neural network designed for pitch estimation directly from time domain waveform inputs. It processes raw audio signals, making it robust to various types of noise and distortion\n",
    "\n",
    "        `Audio speech to text`: \n",
    "    1. Wav2Vec converts audio speech signals into textual representations\n",
    "    2. Wav2Ver2 results in various speech recognition benchmarks and is widely used in industry and academia\n",
    "\n",
    "    - models for video domain:\n",
    "        - `video classification`: \n",
    "        1. VideoMAE is a video classification model using a masked autoencoder architecture\n",
    "        2. ViViT uses a transformer based architecture specifically tailored for video classification. It processes video data by applying self-attention mechanisms to capture long range dependencies\n",
    "\n",
    "        - `video generation`:\n",
    "        1. VideoFlow Encoder is  component of a video generation model that extracts high level features from input video frames. \n",
    "        2. VideoFlow Generator is another component of a video geneeration model that takes the encoded features from the videoFlow encoder and generates new video frames. \n",
    "        3. Tweening Conv3D is a video generation model that focuses on generating intermediate frames between two given frames. \n",
    "\n",
    "## Advantages of Transfer Learning\n",
    "\n",
    "- Reducing training time\n",
    "- Enhanced efficiency in deploying multiple deep learning models\n",
    "- Better model training using simulations instead of resource- intensive real world environments\n",
    "\n",
    "    - Transfer learning allows a pre-trained model to be fine-tuned for other task, reducing the need for massive dataset each time.  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
