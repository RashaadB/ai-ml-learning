{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e835fe0",
   "metadata": {},
   "source": [
    "## Understanding Feature Vectors\n",
    "\n",
    "- A vector is a mathematical representation of a word or a sequence of words. \n",
    "- used to capture semantic meaning of words and their relationships in a numerical format. \n",
    "- The format can be easily processed by machine learning algorithms. \n",
    "\n",
    "## Word Analogies\n",
    "- Word analogies involve identifying relationships between words and then using these relationships to find missing or analogous words. \n",
    "- Word analogies can often be solved using vector arithmetic\n",
    "- Vector distance is used to find the closest match for a missing word in a word pair\n",
    "\n",
    "## Distance Calculation\n",
    "- The distance measure between the word vectors enables the assessment of both similarities and differences between the words. \n",
    "- The distances can be measured as:\n",
    "    - Euclidean Distance\n",
    "    - Manhattan Distance\n",
    "    - Cosine Distance\n",
    "\n",
    "## Text Vectorization Techniques\n",
    "- There are various techniques available for conversion of text to vector. Some of the most common techniques used include:\n",
    "    - Bag of words\n",
    "    - N-grams\n",
    "    - TF-IDF\n",
    "    - Word embeddings\n",
    "\n",
    "## One Hot Encoding\n",
    "- one hot encoding involves representing words or tokens in a text as binary vectors\n",
    "- Treats each word in the vocabulary as a class or category\n",
    "- Assign vector value 1 where the word is present and 0 at other places\n",
    "- This binary representation transforms of text data into a machine learning friendly format, enabling effective processing analysis of categorical information by the model. \n",
    "- As the vocabulary size increases, the one hot encoded vectors become larger and sparser\n",
    "- The high dimensionality and sparsity contribute to increased memory requirements, affecting storage efficiency\n",
    "\n",
    "## Bag of words\n",
    "- A bag of words is a representation of a text that describes the occurrence of words within a document\n",
    "- The bag of words model extracts features from text to represent the data. It models the text using a machine learning algorithm\n",
    "\n",
    "    - Tokenization: While creating the bag of words, tokenized word of each observation is used. \n",
    "    - Scoring mechanism: Document vectors are created using scoring mechanism that included word hashing or boolean value scoring\n",
    "    - Process: These tokenized words are used to create a vocabulary by listing all unique words \n",
    "\n",
    "    - Term: each processed word is called Term\n",
    "\n",
    "    - Term Matrix: Matrix showing frequency of each term occurrence in documents\n",
    "\n",
    "    - Term Frequency: Frequency of a term occurrence in a document\n",
    "\n",
    "## TF-IDF\n",
    "- Bag of words assumes that each word is equally important. but each word still has its own weight based on the context\n",
    "- Term Frequency- Inverse Document Frequency is a numerical statistic that reflects the importance of a word in a document relative to a collection of documents\n",
    "    - Term Frquency: measures how often a term appears in a document\n",
    "    - Inverse Document Frequency: Measures how important a term is across a collection of documents\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
